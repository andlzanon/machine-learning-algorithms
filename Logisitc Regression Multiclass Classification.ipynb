{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "egyptian-portugal",
   "metadata": {},
   "source": [
    "# Logistic Regression for Multiclass Classification with PyTorch\n",
    "\n",
    "This is a simple implementation of Logistic Regression for multiclass classification on the Iris dataset available in https://archive.ics.uci.edu/ml/datasets/iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "powerful-neighbor",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "champion-recipient",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "0                5.1               3.5                1.4               0.2   \n",
       "1                4.9               3.0                1.4               0.2   \n",
       "2                4.7               3.2                1.3               0.2   \n",
       "3                4.6               3.1                1.5               0.2   \n",
       "4                5.0               3.6                1.4               0.2   \n",
       "\n",
       "   target  \n",
       "0     0.0  \n",
       "1     0.0  \n",
       "2     0.0  \n",
       "3     0.0  \n",
       "4     0.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read iris dataset \n",
    "iris = pd.read_csv(\"./datasets/iris.csv\")\n",
    "iris.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "close-simpson",
   "metadata": {},
   "source": [
    "# Architecture\n",
    "This is an image that represents exactly the model implemented, there are four features in the Iris dataset, however, since there are three main targets there will be 3 output nodes after the SoftMax activation function since it is a multiclass and not a binary classification\n",
    "\n",
    "<img src=https://az712634.vo.msecnd.net/tutorials/Logistic-Regression/LogisticRegression_Image_3.jpg alt=\"Logistic Regression scheme\" width='700'>\n",
    "Image source https://az712634.vo.msecnd.net/tutorials/Logistic-Regression/LogisticRegression_Image_3.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "through-groove",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class of Logistic Regression representing image, the activation function however is log softmax due to classification task\n",
    "class LogisticRegression(nn.Module):\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super(LogisticRegression, self).__init__()\n",
    "        self.h1 = nn.Linear(in_features, out_features)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x = F.sigmoid(self.h1(x)) for linear classification \n",
    "        # x = F.softmax(self.h1(x))\n",
    "        x = F.log_softmax(self.h1(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "permanent-faith",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set seed and create object model\n",
    "torch.manual_seed(30)\n",
    "model = LogisticRegression(in_features=4, out_features=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "addressed-recall",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset split\n",
    "X = iris.drop('target',axis=1).values\n",
    "y = iris['target'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=30)\n",
    "\n",
    "X_train = torch.FloatTensor(X_train)\n",
    "X_test = torch.FloatTensor(X_test)\n",
    "y_train = torch.LongTensor(y_train)\n",
    "y_test = torch.LongTensor(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "contemporary-decimal",
   "metadata": {},
   "outputs": [],
   "source": [
    " # setting the Loss function and the optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "widespread-instrument",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andre\\anaconda3\\envs\\pytorchenv\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  1  loss: 1.58034265\n",
      "epoch: 11  loss: 0.90026951\n",
      "epoch: 21  loss: 0.86009121\n",
      "epoch: 31  loss: 0.76776212\n",
      "epoch: 41  loss: 0.70906419\n",
      "epoch: 51  loss: 0.65633476\n",
      "epoch: 61  loss: 0.61673886\n",
      "epoch: 71  loss: 0.58355200\n",
      "epoch: 81  loss: 0.55582446\n",
      "epoch: 91  loss: 0.53192705\n",
      "epoch: 101  loss: 0.51103318\n",
      "epoch: 111  loss: 0.49243772\n",
      "epoch: 121  loss: 0.47567213\n",
      "epoch: 131  loss: 0.46038008\n",
      "epoch: 141  loss: 0.44630119\n",
      "epoch: 151  loss: 0.43323621\n",
      "epoch: 161  loss: 0.42103329\n",
      "epoch: 171  loss: 0.40957388\n",
      "epoch: 181  loss: 0.39876375\n",
      "epoch: 191  loss: 0.38852760\n",
      "epoch: 201  loss: 0.37880385\n",
      "epoch: 211  loss: 0.36954206\n",
      "epoch: 221  loss: 0.36070043\n",
      "epoch: 231  loss: 0.35224384\n",
      "epoch: 241  loss: 0.34414205\n",
      "epoch: 251  loss: 0.33636969\n",
      "epoch: 261  loss: 0.32890433\n",
      "epoch: 271  loss: 0.32172659\n",
      "epoch: 281  loss: 0.31481907\n",
      "epoch: 291  loss: 0.30816647\n",
      "epoch: 301  loss: 0.30175522\n",
      "epoch: 311  loss: 0.29557228\n",
      "epoch: 321  loss: 0.28960648\n",
      "epoch: 331  loss: 0.28384724\n",
      "epoch: 341  loss: 0.27828491\n",
      "epoch: 351  loss: 0.27291021\n",
      "epoch: 361  loss: 0.26771489\n",
      "epoch: 371  loss: 0.26269099\n",
      "epoch: 381  loss: 0.25783110\n",
      "epoch: 391  loss: 0.25312799\n",
      "epoch: 401  loss: 0.24857548\n",
      "epoch: 411  loss: 0.24416678\n",
      "epoch: 421  loss: 0.23989636\n",
      "epoch: 431  loss: 0.23575839\n",
      "epoch: 441  loss: 0.23174749\n",
      "epoch: 451  loss: 0.22785878\n",
      "epoch: 461  loss: 0.22408728\n",
      "epoch: 471  loss: 0.22042820\n",
      "epoch: 481  loss: 0.21687730\n",
      "epoch: 491  loss: 0.21343036\n",
      "epoch: 501  loss: 0.21008345\n",
      "epoch: 511  loss: 0.20683271\n",
      "epoch: 521  loss: 0.20367435\n",
      "epoch: 531  loss: 0.20060512\n",
      "epoch: 541  loss: 0.19762151\n",
      "epoch: 551  loss: 0.19472042\n",
      "epoch: 561  loss: 0.19189864\n",
      "epoch: 571  loss: 0.18915352\n",
      "epoch: 581  loss: 0.18648218\n",
      "epoch: 591  loss: 0.18388186\n",
      "epoch: 601  loss: 0.18135020\n",
      "epoch: 611  loss: 0.17888467\n",
      "epoch: 621  loss: 0.17648290\n",
      "epoch: 631  loss: 0.17414270\n",
      "epoch: 641  loss: 0.17186199\n",
      "epoch: 651  loss: 0.16963860\n",
      "epoch: 661  loss: 0.16747063\n",
      "epoch: 671  loss: 0.16535631\n",
      "epoch: 681  loss: 0.16329367\n",
      "epoch: 691  loss: 0.16128112\n",
      "epoch: 701  loss: 0.15931691\n",
      "epoch: 711  loss: 0.15739943\n",
      "epoch: 721  loss: 0.15552731\n",
      "epoch: 731  loss: 0.15369897\n",
      "epoch: 741  loss: 0.15191302\n",
      "epoch: 751  loss: 0.15016803\n",
      "epoch: 761  loss: 0.14846286\n",
      "epoch: 771  loss: 0.14679618\n",
      "epoch: 781  loss: 0.14516687\n",
      "epoch: 791  loss: 0.14357369\n",
      "epoch: 801  loss: 0.14201555\n",
      "epoch: 811  loss: 0.14049141\n",
      "epoch: 821  loss: 0.13900022\n",
      "epoch: 831  loss: 0.13754101\n",
      "epoch: 841  loss: 0.13611287\n",
      "epoch: 851  loss: 0.13471486\n",
      "epoch: 861  loss: 0.13334604\n",
      "epoch: 871  loss: 0.13200562\n",
      "epoch: 881  loss: 0.13069279\n",
      "epoch: 891  loss: 0.12940678\n",
      "epoch: 901  loss: 0.12814680\n",
      "epoch: 911  loss: 0.12691210\n",
      "epoch: 921  loss: 0.12570201\n",
      "epoch: 931  loss: 0.12451582\n",
      "epoch: 941  loss: 0.12335289\n",
      "epoch: 951  loss: 0.12221263\n",
      "epoch: 961  loss: 0.12109434\n",
      "epoch: 971  loss: 0.11999746\n",
      "epoch: 981  loss: 0.11892145\n",
      "epoch: 991  loss: 0.11786568\n"
     ]
    }
   ],
   "source": [
    "# set number of epochs and train model passing\n",
    "# forward the train set and comparing with real values\n",
    "epochs = 1000\n",
    "losses = []\n",
    "\n",
    "for i in range(epochs):\n",
    "    i+=1\n",
    "    y_pred = model.forward(X_train)\n",
    "    loss = criterion(y_pred, y_train)\n",
    "    losses.append(loss)\n",
    "    \n",
    "    if i%10 == 1:\n",
    "        print(f'epoch: {i:2}  loss: {loss.item():10.8f}')\n",
    "    \n",
    "    # compute the loss, gradients and update parameters\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "documented-yemen",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot errors by epochs \n",
    "plt.plot(range(epochs), losses)\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('epoch');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "rubber-namibia",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-3.4457e-02, -3.3852e+00, -1.6555e+01],\n",
      "        [-1.0290e-02, -4.5817e+00, -1.7407e+01],\n",
      "        [-4.2895e-02, -3.1704e+00, -1.5178e+01],\n",
      "        [-9.1725e+00, -2.6424e+00, -7.3966e-02],\n",
      "        [-3.7046e+00, -5.8941e-02, -3.4226e+00],\n",
      "        [-4.1824e+00, -5.3999e-02, -3.2886e+00],\n",
      "        [-7.3279e+00, -1.2818e+00, -3.2600e-01],\n",
      "        [-9.1873e+00, -3.1793e+00, -4.2612e-02],\n",
      "        [-4.1997e+00, -5.4993e-02, -3.2569e+00],\n",
      "        [-1.1130e+01, -2.0952e+00, -1.3132e-01],\n",
      "        [-3.3364e-02, -3.4169e+00, -1.5389e+01],\n",
      "        [-9.4581e+00, -2.1556e+00, -1.2320e-01],\n",
      "        [-3.2044e+00, -6.2094e-02, -3.9310e+00],\n",
      "        [-3.9906e+00, -1.0092e-01, -2.5574e+00],\n",
      "        [-5.3734e-02, -2.9505e+00, -1.4592e+01],\n",
      "        [-4.2127e+00, -6.7555e-02, -2.9854e+00],\n",
      "        [-4.0522e-03, -5.5105e+00, -2.0262e+01],\n",
      "        [-4.2502e-02, -3.1794e+00, -1.5669e+01],\n",
      "        [-5.6021e-02, -2.9099e+00, -1.4842e+01],\n",
      "        [-7.1097e+00, -5.4733e-01, -8.6585e-01],\n",
      "        [-6.8773e+00, -5.3654e-01, -8.8140e-01],\n",
      "        [-2.0816e-02, -3.8824e+00, -1.6130e+01],\n",
      "        [-1.3049e-02, -4.3455e+00, -1.7807e+01],\n",
      "        [-1.6263e-02, -4.1270e+00, -1.7420e+01],\n",
      "        [-1.3058e+01, -3.5578e+00, -2.8917e-02],\n",
      "        [-1.1601e+01, -4.1101e+00, -1.6551e-02],\n",
      "        [-5.6731e+00, -1.0690e+00, -4.2583e-01],\n",
      "        [-1.0486e+01, -4.4552e+00, -1.1715e-02],\n",
      "        [-2.0802e-02, -3.8831e+00, -1.6557e+01],\n",
      "        [-5.9516e+00, -1.2464e-01, -2.1664e+00]])\n",
      "0.13744864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andre\\anaconda3\\envs\\pytorchenv\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "# evaluate the entire test set\n",
    "with torch.no_grad():\n",
    "    y_val = model.forward(X_test)\n",
    "    print(y_val)\n",
    "    loss = criterion(y_val, y_test)\n",
    "print(f'{loss:.8f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "thousand-aquarium",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1. tensor([ -0.0345,  -3.3852, -16.5555]) 0 0\n",
      " 2. tensor([-1.0290e-02, -4.5817e+00, -1.7407e+01]) 0 0\n",
      " 3. tensor([ -0.0429,  -3.1704, -15.1782]) 0 0\n",
      " 4. tensor([-9.1725, -2.6424, -0.0740])    2 2\n",
      " 5. tensor([-3.7046, -0.0589, -3.4226])    1 1\n",
      " 6. tensor([-4.1824, -0.0540, -3.2886])    1 1\n",
      " 7. tensor([-7.3279, -1.2818, -0.3260])    2 2\n",
      " 8. tensor([-9.1873, -3.1793, -0.0426])    2 2\n",
      " 9. tensor([-4.1997, -0.0550, -3.2569])    1 1\n",
      "10. tensor([-11.1300,  -2.0952,  -0.1313]) 2 2\n",
      "11. tensor([ -0.0334,  -3.4169, -15.3894]) 0 0\n",
      "12. tensor([-9.4581, -2.1555, -0.1232])    2 2\n",
      "13. tensor([-3.2044, -0.0621, -3.9310])    1 1\n",
      "14. tensor([-3.9906, -0.1009, -2.5574])    1 1\n",
      "15. tensor([ -0.0537,  -2.9505, -14.5924]) 0 0\n",
      "16. tensor([-4.2127, -0.0676, -2.9854])    1 1\n",
      "17. tensor([-4.0522e-03, -5.5105e+00, -2.0262e+01]) 0 0\n",
      "18. tensor([ -0.0425,  -3.1794, -15.6688]) 0 0\n",
      "19. tensor([ -0.0560,  -2.9099, -14.8420]) 0 0\n",
      "20. tensor([-7.1097, -0.5473, -0.8659])    1 1\n",
      "21. tensor([-6.8773, -0.5365, -0.8814])    1 2\n",
      "22. tensor([ -0.0208,  -3.8824, -16.1300]) 0 0\n",
      "23. tensor([-1.3049e-02, -4.3455e+00, -1.7807e+01]) 0 0\n",
      "24. tensor([-1.6263e-02, -4.1270e+00, -1.7420e+01]) 0 0\n",
      "25. tensor([-13.0582,  -3.5578,  -0.0289]) 2 2\n",
      "26. tensor([-11.6007,  -4.1101,  -0.0166]) 2 2\n",
      "27. tensor([-5.6731, -1.0690, -0.4258])    2 1\n",
      "28. tensor([-10.4863,  -4.4552,  -0.0117]) 2 2\n",
      "29. tensor([ -0.0208,  -3.8831, -16.5566]) 0 0\n",
      "30. tensor([-5.9516, -0.1246, -2.1664])    1 1\n",
      "\n",
      "28 out of 30 = 93.33% correct\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andre\\anaconda3\\envs\\pytorchenv\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "# verify number of correct predictions\n",
    "correct = 0\n",
    "with torch.no_grad():\n",
    "    for i,data in enumerate(X_test):\n",
    "        y_val = model.forward(data)\n",
    "        print(f'{i+1:2}. {str(y_val):38} {str(y_val.argmax().item())} {y_test[i]}')\n",
    "        if y_val.argmax().item() == y_test[i]:\n",
    "            correct += 1\n",
    "print(f'\\n{correct} out of {len(y_test)} = {100*correct/len(y_test):.2f}% correct')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
